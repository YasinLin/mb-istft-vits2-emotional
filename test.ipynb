{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5970442f-9828-4e8e-bb10-d5c15f47911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 768])\n",
      "[1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1]\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 2 torch.Size([2, 768])\n",
      "torch.Size([768]) 1 torch.Size([1, 768])\n",
      "torch.Size([768, 65])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./models/bert-prosody\")\n",
    "\n",
    "models = dict()\n",
    "\n",
    "\n",
    "def get_bert_feature(text, word2ph, device=None):\n",
    "    if (\n",
    "        sys.platform == \"darwin\"\n",
    "        and torch.backends.mps.is_available()\n",
    "        and device == \"cpu\"\n",
    "    ):\n",
    "        device = \"mps\"\n",
    "    if not device:\n",
    "        device = \"cuda\"\n",
    "    if device not in models.keys():\n",
    "        models[device] = AutoModelForMaskedLM.from_pretrained(\n",
    "            \"./models/bert-prosody\"\n",
    "        ).to(device)\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "        for i in inputs:\n",
    "            inputs[i] = inputs[i].to(device)\n",
    "        res = models[device](**inputs, output_hidden_states=True)\n",
    "        res = torch.cat(res[\"hidden_states\"][-3:-2], -1)[0].cpu()\n",
    "\n",
    "    assert len(word2ph) == len(text) + 2\n",
    "    word2phone = word2ph\n",
    "    phone_level_feature = []\n",
    "    for i in range(len(word2phone)):\n",
    "        repeat_feature = res[i].repeat(word2phone[i], 1)\n",
    "        phone_level_feature.append(repeat_feature)\n",
    "\n",
    "    phone_level_feature = torch.cat(phone_level_feature, dim=0)\n",
    "\n",
    "    return phone_level_feature.T\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torch\n",
    "\n",
    "    word_level_feature = torch.rand(38, 768)  # 12个词,每个词1024维特征\n",
    "    word2phone = [\n",
    "        1,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        1,\n",
    "    ]\n",
    "\n",
    "    # 计算总帧数\n",
    "    total_frames = sum(word2phone)\n",
    "    print(word_level_feature.shape)\n",
    "    print(word2phone)\n",
    "    phone_level_feature = []\n",
    "    for i in range(len(word2phone)):\n",
    "\n",
    "        # 对每个词重复word2phone[i]次\n",
    "        repeat_feature = word_level_feature[i].repeat(word2phone[i], 1)\n",
    "        print(word_level_feature[i].shape,word2phone[i],repeat_feature.shape)\n",
    "        \n",
    "        phone_level_feature.append(repeat_feature)\n",
    "\n",
    "    phone_level_feature = torch.cat(phone_level_feature, dim=0)\n",
    "    print(phone_level_feature.T.shape)  # torch.Size([36, 1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f35e444-f46c-4643-bac4-8ad7f63a078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "bert_filename = \"dataset/aishell3_16k/SSB00110010.bert.npy\"\n",
    "bertpt = torch.FloatTensor(np.load(bert_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5dd55c-89c9-4daa-ac3d-8104bc7f94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4332, -0.4008,  0.2471,  ..., -0.3400,  0.5843,  0.3035],\n",
      "        [-0.2315, -0.8457, -0.4866,  ..., -0.3133,  0.0420,  0.2558],\n",
      "        [ 0.5430, -1.2423,  0.5775,  ..., -0.9140, -0.1976, -0.2772],\n",
      "        ...,\n",
      "        [-0.5502, -0.6223,  0.3056,  ...,  0.4754, -0.0448,  0.4808],\n",
      "        [ 0.4328, -0.3808,  0.9168,  ..., -1.1270,  0.1758,  0.1739],\n",
      "        [-0.5201,  0.2979, -0.6583,  ..., -0.8205,  0.1313, -0.9362]])\n"
     ]
    }
   ],
   "source": [
    "print(bertpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4755a6-5758-4517-9ed1-057a7659bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 256])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(bertpt.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d80499c-ef79-4302-a05b-901fea51e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from prosody import TTSProsody\n",
    "prosody = TTSProsody(\"models/bert-prosody/\", \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0263603d-4638-460d-97e1-e71486178b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prosody.get_char_embeds(\"你好\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8fc8929-ee8d-46c7-8831-70d3bf7fcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.4332184  -0.40082648  0.2470586  ... -0.34002692  0.58425456\n",
      "   0.30349484]\n",
      " [-0.4332184  -0.40082648  0.2470586  ... -0.34002692  0.58425456\n",
      "   0.30349484]\n",
      " [-0.23147522 -0.8456656  -0.48662975 ... -0.31329533  0.0419562\n",
      "   0.25580218]\n",
      " ...\n",
      " [-0.55024457 -0.6222654   0.30557343 ...  0.47536862 -0.04482635\n",
      "   0.4808462 ]\n",
      " [ 0.43279293 -0.38081172  0.91682386 ... -1.126965    0.17581624\n",
      "   0.1738908 ]\n",
      " [-0.5200584   0.29791054 -0.6582804  ... -0.8204557   0.1312837\n",
      "  -0.93621165]]\n"
     ]
    }
   ],
   "source": [
    "emb = prosody.expand_for_phone(bertpt,[2,2,2,2,1,1,1,1,1,1,1,1,1,1])\n",
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c03af4aa-815e-40c2-a9a9-72ed062081af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 256)\n"
     ]
    }
   ],
   "source": [
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eecb5d6-bbe9-4e6f-9661-b6a3add8c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pypinyin import lazy_pinyin, BOPOMOFO\n",
    "from text.cleaners import chinese_cleaners2\n",
    "import text\n",
    "\n",
    "from bert_extract import VITS_BERT\n",
    "\n",
    "vits_bert = VITS_BERT(\"models/bert-prosody/\", \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e89887-cd96-48c4-935d-5e2d8797c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"比方说，“华尔街日报”就很好。...\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dec401-4ab5-42db-9b8b-9e691bce3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.636 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ㄅㄧˇㄈㄤˉㄕㄨㄛˉ，“ㄏㄨㄚˊㄦˇㄐㄧㄝˉㄖˋㄅㄠˋ”ㄐㄧㄡˋㄏㄣˇㄏㄠˇ。..._ 44\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bopomofos = chinese_cleaners2(input)\n",
    "s = text.cleaned_text_to_sequence(bopomofos)\n",
    "\n",
    "print(bopomofos,len(bopomofos))\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4199a-e37f-4e8d-9ced-e0bfecbf97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vits_bert.chinese_to_bert(input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f763cb-139d-4c65-a33c-549765941c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filelist in [\"\"]:\n",
    "    print(\"START:\", filelist)\n",
    "    filepaths_and_text = load_filepaths_and_text(filelist)\n",
    "    for i in range(len(filepaths_and_text)):\n",
    "      original_text = filepaths_and_text[i][args.text_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vits",
   "language": "python",
   "name": "vits"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
